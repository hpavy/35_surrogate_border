{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "from model import PINNs\n",
    "import pandas as pd\n",
    "from utils import charge_data\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from model import PINNs\n",
    "from utils import charge_data\n",
    "import json\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import os\n",
    "import numpy as np\n",
    "import time as time\n",
    "import pandas as pd\n",
    "from constants import DICT_CASE, DICT_Y0, PARAM_ADIM\n",
    "from geometry import RectangleWithoutCylinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"12_huge_rnn\"\n",
    "epoch = \"epoch1000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_adim = {\"V\": 1.0, \"L\": 0.025, \"rho\": 1.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"results/\" + folder_name + \"/hyper_param.json\", \"r\") as file:\n",
    "    hyper_param = json.load(file)\n",
    "model = PINNs(hyper_param)\n",
    "checkpoint = torch.load(\n",
    "    \"results/\" + folder_name + \"/\" + epoch + \"/\" + \"model_weights.pth\",\n",
    "    map_location=torch.device(\"cpu\"),\n",
    ")\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/'+folder_name+'/mean_std.json') as file: \n",
    "    mean_std = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_flow(\n",
    "    x,\n",
    "    y,\n",
    "    t,\n",
    "    norme_vitesse_data,\n",
    "    norme_vitesse_predict,\n",
    "    name_file,\n",
    "    fps=7,\n",
    "    title=\"Norme vitesse\",\n",
    "):\n",
    "    # Créer une figure et des axes\n",
    "    # Ajuster la taille de la figure\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    # Déterminer les valeurs min et max pour la colormap\n",
    "    vmin = min(np.min(norme_vitesse_data), np.min(norme_vitesse_predict))\n",
    "    vmax = max(np.max(norme_vitesse_data), np.max(norme_vitesse_predict))\n",
    "\n",
    "    # Initialiser les cartes de chaleur\n",
    "    indices = np.where(t == np.min(t))\n",
    "    c1 = ax[0].tripcolor(\n",
    "        x[indices],\n",
    "        y[indices],\n",
    "        norme_vitesse_data[indices],\n",
    "        shading=\"gouraud\",\n",
    "        cmap=\"coolwarm\",\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "    )\n",
    "    c2 = ax[1].tripcolor(\n",
    "        x[indices],\n",
    "        y[indices],\n",
    "        norme_vitesse_predict[indices],\n",
    "        shading=\"gouraud\",\n",
    "        cmap=\"coolwarm\",\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "    )\n",
    "\n",
    "    ax[0].set_title(\"Data\")\n",
    "\n",
    "\n",
    "    ax[1].set_title(\"Predictions\")\n",
    "    ax[0].set_xticks([])  # Enlever les valeurs de l'axe x\n",
    "    ax[0].set_yticks([])  # Enlever les valeurs de l'axe y\n",
    "    ax[1].set_xticks([])  # Enlever les valeurs de l'axe x\n",
    "    ax[1].set_yticks([])  # Enlever les valeurs de l'axe y\n",
    "\n",
    "\n",
    "    # Ajouter une barre de couleur\n",
    "    cbar = fig.colorbar(c1, ax=ax, orientation=\"vertical\", label=f\"{title}\")\n",
    "\n",
    "    # Fonction d'initialisation\n",
    "    def init():\n",
    "        return c1, c2\n",
    "\n",
    "    # Fonction d'animation\n",
    "    def update(frame):\n",
    "        print(frame)\n",
    "        time = list(set(t))\n",
    "        time.sort()\n",
    "        indices = np.where(t == time[frame])\n",
    "\n",
    "        # Mettre à jour la première carte de chaleur\n",
    "        c1.set_array(norme_vitesse_data[indices].flatten())\n",
    "        ax[0].set_title(\"Data\", fontsize=15, fontweight='bold')\n",
    "\n",
    "        # Mettre à jour la deuxième carte de chaleur\n",
    "        c2.set_array(norme_vitesse_predict[indices].flatten())\n",
    "        ax[1].set_title(\"Predictions\", fontsize=15, fontweight='bold')\n",
    "\n",
    "        # Titre général\n",
    "        plt.suptitle(f\"{title} at t={time[frame]:.2f}\", fontsize=15)\n",
    "\n",
    "        return c1, c2\n",
    "\n",
    "    # Créer l'animation\n",
    "    ani = FuncAnimation(\n",
    "        fig, update, frames=len(set(t)), init_func=init, blit=False, repeat=True\n",
    "    )\n",
    "    ani.save(name_file, writer=\"pillow\", fps=fps)\n",
    "\n",
    "    plt.show()  # Afficher la figure à la fin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = [\n",
    "    4,\n",
    "    7,\n",
    "    10,\n",
    "    13, \n",
    "    4,\n",
    "    7,\n",
    "    10,\n",
    "    13\n",
    "]\n",
    "\n",
    "case = [\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "]\n",
    "\n",
    "files = [f'model_{num[k]}_case_{case[k]}.csv' for k in range(len(num))]\n",
    "\n",
    "ya0_L = [DICT_Y0[str(k)] for k in num]\n",
    "H_L = [DICT_CASE[str(k)] for k in case]\n",
    "max_y = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charge_data(hyper_param, param_adim, mean_std):\n",
    "    \"\"\"\n",
    "    Charge the data of X_full, U_full with every points\n",
    "    And X_train, U_train with less points\n",
    "    \"\"\"\n",
    "    # La data\n",
    "    # On adimensionne la data\n",
    "    time_start_charge = time.time()\n",
    "    nb_simu = len(hyper_param[\"file\"])\n",
    "    x_full, y_full, t_full, ya0_full, w0_full = [], [], [], [], []\n",
    "    u_full, v_full, p_full = [], [], []\n",
    "    x_norm_full, y_norm_full, t_norm_full, ya0_norm_full, w0_norm_full = (\n",
    "        [],\n",
    "        [],\n",
    "        [],\n",
    "        [],\n",
    "        [],\n",
    "    )\n",
    "    u_norm_full, v_norm_full, p_norm_full = [], [], []\n",
    "    H_numpy = np.array(hyper_param[\"H\"])\n",
    "    f_numpy = 0.5 * (H_numpy / hyper_param[\"m\"]) ** 0.5\n",
    "    f = np.min(f_numpy)\n",
    "    t_max = hyper_param[\"t_min\"] + hyper_param[\"nb_period\"] / f\n",
    "    for k in range(nb_simu):\n",
    "        df = pd.read_csv(\"data/\" + hyper_param[\"file\"][k])\n",
    "        df_modified = df.loc[\n",
    "            (df[\"Points:0\"] >= hyper_param[\"x_min\"])\n",
    "            & (df[\"Points:0\"] <= hyper_param[\"x_max\"])\n",
    "            & (df[\"Points:1\"] >= hyper_param[\"y_min\"])\n",
    "            & (df[\"Points:1\"] <= hyper_param[\"y_max\"])\n",
    "            & (df[\"Time\"] > hyper_param[\"t_min\"])\n",
    "            & (df[\"Time\"] < t_max)\n",
    "            & (df[\"Points:2\"] == 0.0)\n",
    "            & (df[\"Points:0\"] ** 2 + df[\"Points:1\"] ** 2 > hyper_param['r_min'] ** 2),\n",
    "            :,\n",
    "        ].copy()\n",
    "        df_modified.loc[:, \"ya0\"] = hyper_param[\"ya0\"][k]\n",
    "        df_modified.loc[:, \"w0\"] = (\n",
    "            torch.pi * (hyper_param[\"H\"][k] / hyper_param[\"m\"]) ** 0.5\n",
    "        )\n",
    "\n",
    "        # Adimensionnement\n",
    "        x_full.append(\n",
    "            torch.tensor(df_modified[\"Points:0\"].to_numpy(), dtype=torch.float32)\n",
    "            / param_adim[\"L\"]\n",
    "        )\n",
    "        y_full.append(\n",
    "            torch.tensor(df_modified[\"Points:1\"].to_numpy(), dtype=torch.float32)\n",
    "            / param_adim[\"L\"]\n",
    "        )\n",
    "        f_flow = f_numpy[k]\n",
    "        time_without_modulo = df_modified[\"Time\"].to_numpy() - hyper_param['t_min']\n",
    "        time_with_modulo = hyper_param['t_min'] + time_without_modulo % (1/f_flow)\n",
    "        t_full.append(\n",
    "            torch.tensor(time_with_modulo, dtype=torch.float32)\n",
    "            / (param_adim[\"L\"] / param_adim[\"V\"])\n",
    "        )\n",
    "        ya0_full.append(\n",
    "            torch.tensor(df_modified[\"ya0\"].to_numpy(), dtype=torch.float32)\n",
    "            / param_adim[\"L\"]\n",
    "        )\n",
    "        w0_full.append(\n",
    "            torch.tensor(df_modified[\"w0\"].to_numpy(), dtype=torch.float32)\n",
    "            / (param_adim[\"V\"] / param_adim[\"L\"])\n",
    "        )\n",
    "        u_full.append(\n",
    "            torch.tensor(df_modified[\"Velocity:0\"].to_numpy(), dtype=torch.float32)\n",
    "            / param_adim[\"V\"]\n",
    "        )\n",
    "        v_full.append(\n",
    "            torch.tensor(df_modified[\"Velocity:1\"].to_numpy(), dtype=torch.float32)\n",
    "            / param_adim[\"V\"]\n",
    "        )\n",
    "        p_full.append(\n",
    "            torch.tensor(df_modified[\"Pressure\"].to_numpy(), dtype=torch.float32)\n",
    "            / ((param_adim[\"V\"] ** 2) * param_adim[\"rho\"])\n",
    "        )\n",
    "        print(f\"fichier n°{k} chargé\")\n",
    "        \n",
    "    if nb_simu == 1:\n",
    "        w0_std = torch.ones(1)\n",
    "        ya0_std = torch.ones(1)\n",
    "    else:\n",
    "        w0_std = torch.cat([w0 for w0 in w0_full], dim=0).std()\n",
    "        ya0_std = torch.cat([ya0 for ya0 in ya0_full], dim=0).std()\n",
    "\n",
    "\n",
    "    X_full = torch.zeros((0, 5))\n",
    "    U_full = torch.zeros((0, 3))\n",
    "    for k in range(nb_simu):\n",
    "        # Normalisation Z\n",
    "        x_norm_full.append((x_full[k] - mean_std[\"x_mean\"]) / mean_std[\"x_std\"])\n",
    "        y_norm_full.append((y_full[k] - mean_std[\"y_mean\"]) / mean_std[\"y_std\"])\n",
    "        t_norm_full.append((t_full[k] - mean_std[\"t_mean\"]) / mean_std[\"t_std\"])\n",
    "        ya0_norm_full.append((ya0_full[k] - mean_std[\"ya0_mean\"]) / mean_std[\"ya0_std\"])\n",
    "        w0_norm_full.append((w0_full[k] - mean_std[\"w0_mean\"]) / mean_std[\"w0_std\"])\n",
    "        p_norm_full.append((p_full[k] - mean_std[\"p_mean\"]) / mean_std[\"p_std\"])\n",
    "        u_norm_full.append((u_full[k] - mean_std[\"u_mean\"]) / mean_std[\"u_std\"])\n",
    "        v_norm_full.append((v_full[k] - mean_std[\"v_mean\"]) / mean_std[\"v_std\"])\n",
    "        X_full = torch.cat(\n",
    "            (\n",
    "                X_full,\n",
    "                torch.stack(\n",
    "                    (\n",
    "                        x_norm_full[-1],\n",
    "                        y_norm_full[-1],\n",
    "                        t_norm_full[-1],\n",
    "                        ya0_norm_full[-1],\n",
    "                        w0_norm_full[-1],\n",
    "                    ),\n",
    "                    dim=1,\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "        U_full = torch.cat(\n",
    "            (\n",
    "                U_full,\n",
    "                torch.stack((u_norm_full[-1], v_norm_full[-1], p_norm_full[-1]), dim=1),\n",
    "            )\n",
    "        )\n",
    "\n",
    "  \n",
    "    return (\n",
    "        X_full,\n",
    "        U_full\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/model_4_case_1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 12\u001b[0m\n\u001b[1;32m      5\u001b[0m hyper_param[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mya0\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [DICT_Y0[\u001b[38;5;28mstr\u001b[39m(k)] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m hyper_param[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m      6\u001b[0m hyper_param[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_case_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcase_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m num_, case_ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(hyper_param[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum\u001b[39m\u001b[38;5;124m'\u001b[39m], hyper_param[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcase\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m     ]\n\u001b[1;32m      9\u001b[0m (\n\u001b[1;32m     10\u001b[0m     X_full,\n\u001b[1;32m     11\u001b[0m     U_full,\n\u001b[0;32m---> 12\u001b[0m ) \u001b[38;5;241m=\u001b[39m charge_data(hyper_param, PARAM_ADIM, mean_std)\n\u001b[1;32m     14\u001b[0m U_predict \u001b[38;5;241m=\u001b[39m model(X_full)\n\u001b[1;32m     16\u001b[0m U_predict \u001b[38;5;241m=\u001b[39m U_predict\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m, in \u001b[0;36mcharge_data\u001b[0;34m(hyper_param, param_adim, mean_std)\u001b[0m\n\u001b[1;32m     23\u001b[0m t_max \u001b[38;5;241m=\u001b[39m hyper_param[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt_min\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m hyper_param[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnb_period\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m f\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nb_simu):\n\u001b[0;32m---> 25\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m hyper_param[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m][k])\n\u001b[1;32m     26\u001b[0m     df_modified \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[\n\u001b[1;32m     27\u001b[0m         (df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPoints:0\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m hyper_param[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_min\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPoints:0\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m hyper_param[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_max\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m         :,\n\u001b[1;32m     36\u001b[0m     ]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     37\u001b[0m     df_modified\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mya0\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m hyper_param[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mya0\u001b[39m\u001b[38;5;124m\"\u001b[39m][k]\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/model_4_case_1.csv'"
     ]
    }
   ],
   "source": [
    "for k in range(1):\n",
    "    hyper_param['num'] = [num[k]]\n",
    "    hyper_param['case'] [case[k]]\n",
    "    hyper_param['H'] = [DICT_CASE[str(k)] for k in hyper_param['case']]\n",
    "    hyper_param['ya0'] = [DICT_Y0[str(k)] for k in hyper_param['num']]\n",
    "    hyper_param['file'] = [\n",
    "        f\"model_{num_}_case_{case_}.csv\" for num_, case_ in zip(hyper_param['num'], hyper_param['case'])\n",
    "        ]\n",
    "    (\n",
    "        X_full,\n",
    "        U_full,\n",
    "    ) = charge_data(hyper_param, PARAM_ADIM, mean_std)\n",
    "    \n",
    "    U_predict = model(X_full)\n",
    "\n",
    "    U_predict = U_predict.detach().numpy()\n",
    "    X_full = X_full.numpy()\n",
    "    U_full = U_full.numpy()\n",
    "    x_data = (X_full[:, 0]*mean_std['x_std'] + mean_std['x_mean']) * PARAM_ADIM['L']\n",
    "    y_data = (X_full[:, 1]*mean_std['y_std'] + mean_std['y_mean']) * PARAM_ADIM['L']\n",
    "    t_data = (X_full[:, 2]*mean_std['t_std'] + mean_std['t_mean']) * (PARAM_ADIM['L']/PARAM_ADIM['V'])\n",
    "    u_data = (U_full[:, 0]*mean_std['u_std'] + mean_std['u_mean']) * PARAM_ADIM['V']\n",
    "    v_data = (U_full[:, 1]*mean_std['v_std'] + mean_std['v_mean']) * PARAM_ADIM['V']\n",
    "    p_data = (U_full[:, 2]*mean_std['p_std'] + mean_std['p_mean']) * ((PARAM_ADIM[\"V\"] ** 2) * PARAM_ADIM[\"rho\"])\n",
    "    u_predict = (U_predict[:, 0]*mean_std['u_std'] + mean_std['u_mean']) * PARAM_ADIM['V']\n",
    "    v_predict = (U_predict[:, 1]*mean_std['v_std'] + mean_std['v_mean']) * PARAM_ADIM['V']\n",
    "    p_predict = (U_predict[:, 2]*mean_std['p_std'] + mean_std['p_mean']) * ((PARAM_ADIM[\"V\"] ** 2) * PARAM_ADIM[\"rho\"])\n",
    "    norme_vitesse_data = (u_data**2 + v_data**2)**0.5\n",
    "    norme_vitesse_predict = (u_predict**2 + v_predict**2)**0.5\n",
    "    plot_flow(\n",
    "    x_data,\n",
    "    y_data,\n",
    "    t_data,\n",
    "    norme_vitesse_data,\n",
    "    norme_vitesse_predict,\n",
    "    'results/' + folder_name + '/velocity_norm.gif',\n",
    "    fps=20,\n",
    "    title=\"Velocity norm\",\n",
    "    )\n",
    "    plot_flow(\n",
    "    x_data,\n",
    "    y_data,\n",
    "    t_data,\n",
    "    p_data,\n",
    "    p_predict,\n",
    "    'results/' + folder_name + '/pression.gif',\n",
    "    fps=20,\n",
    "    title=\"Pressure\",\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_data = (U_full[:, 0]*mean_std['u_std'].item() + mean_std['u_mean'].item()) * PARAM_ADIM['V']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8194908499717712"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std['u_mean'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3965734541416168"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_std['u_std'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.numpy>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
